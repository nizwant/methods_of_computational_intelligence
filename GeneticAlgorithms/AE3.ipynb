{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /Users/mat/opt/anaconda3/envs/asseco/lib/python3.10/site-packages (0.0.3)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialization_builder import InitializationBuilder\n",
    "from activation_builder import ActivationBuilder\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    __slots__ = [\n",
    "        \"nodes_in\",\n",
    "        \"nodes_out\",\n",
    "        \"weights\",\n",
    "        \"weights_gradient\",\n",
    "        \"biases\",\n",
    "        \"biases_gradient\",\n",
    "        \"activation\",\n",
    "        \"a\",\n",
    "        \"z\",\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes_in,\n",
    "        nodes_out,\n",
    "        activation=\"sigmoid\",\n",
    "        weight_initialization=\"he\",\n",
    "        bias_initialization=\"zero\",\n",
    "    ):\n",
    "\n",
    "        self.nodes_in = nodes_in\n",
    "        self.nodes_out = nodes_out\n",
    "\n",
    "        self.weights = InitializationBuilder.get_initialization(\n",
    "            weight_initialization, nodes_out, nodes_in\n",
    "        )\n",
    "\n",
    "        self.weights_gradient = InitializationBuilder.get_initialization(\n",
    "            \"zero\", nodes_out, nodes_in\n",
    "        )\n",
    "\n",
    "        self.biases = InitializationBuilder.get_initialization(\n",
    "            bias_initialization, nodes_out, 1\n",
    "        )\n",
    "        self.biases_gradient = InitializationBuilder.get_initialization(\n",
    "            \"zero\", nodes_out, 1\n",
    "        )\n",
    "\n",
    "        self.activation = ActivationBuilder.get_activation(activation)\n",
    "\n",
    "    def forward(self, a):\n",
    "        self.z = np.dot(self.weights, a) + self.biases\n",
    "        self.a = self.activation.activation(self.z)\n",
    "        return self.a\n",
    "\n",
    "    def report_layer(self, layer_num):\n",
    "        return (\n",
    "            f\"Layer number {layer_num}\\nWeights\\n{self.weights}\\nbiases\\n{self.biases}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cost_function_builder import CostFunctionBuilder\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    __slots__ = [\n",
    "        \"layers\",\n",
    "        \"optimizer\",\n",
    "        \"cost_function\",\n",
    "        \"layer_sizes\",\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cost_function=\"mse\",\n",
    "    ):\n",
    "        self.layers = []\n",
    "        self.layer_sizes = []\n",
    "        self.cost_function = CostFunctionBuilder().build_cost_function(cost_function)\n",
    "\n",
    "    def add_layer(self, layer: Layer):\n",
    "        if not self.layer_sizes:\n",
    "            self.layer_sizes = [layer.nodes_in]\n",
    "        else:\n",
    "            assert (\n",
    "                layer.nodes_in == self.layer_sizes[-1]\n",
    "            ), f\"Output in previous layer doesn't match input in this layer\"\n",
    "        self.layer_sizes.append(layer.nodes_out)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def _forward(self, x: np.ndarray):\n",
    "        if isinstance(x, pd.DataFrame) or isinstance(x, pd.Series):\n",
    "            x = x.to_numpy()\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.reshape(-1, 1)\n",
    "        a = x.T\n",
    "        for layer in self.layers:\n",
    "            a = layer.forward(a)\n",
    "        return a\n",
    "\n",
    "    def predict(self, x: np.ndarray):\n",
    "        return self._forward(x).T\n",
    "\n",
    "    def predict_class(self, x: np.ndarray):\n",
    "        return np.argmax(self.predict(x), axis=1, keepdims=True)\n",
    "\n",
    "    def flatten_weights_and_biases(self):\n",
    "        weights_and_biases = []\n",
    "        for layer in self.layers:\n",
    "            weights_and_biases.append(layer.weights.flatten())\n",
    "            weights_and_biases.append(layer.biases.flatten())\n",
    "        return np.concatenate(weights_and_biases)\n",
    "\n",
    "    def deflatten_weights_and_biases(self, solution):\n",
    "        for layer in self.layers:\n",
    "            layer.weights = solution[: layer.weights.size].reshape(layer.weights.shape)\n",
    "            solution = solution[layer.weights.size :]\n",
    "            layer.biases = solution[: layer.biases.size].reshape(layer.biases.shape)\n",
    "            solution = solution[layer.biases.size :]\n",
    "\n",
    "    def calculate_cost(self, x: np.ndarray, y: np.ndarray):\n",
    "        base_cost = self.cost_function.cost(self.predict(x), y)\n",
    "        return base_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolutionary_Algorithm:\n",
    "    __slots__ = [\n",
    "        \"mutation_rate\",\n",
    "        \"crossover_rate\",\n",
    "        \"number_of_generations\",\n",
    "        \"population_size\",\n",
    "        \"function_to_optimize\",\n",
    "        \"population\",\n",
    "        \"problem_dim\",\n",
    "        \"hall_of_fame\",\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mutation_rate=0.7,\n",
    "        crossover_rate=0.7,\n",
    "        number_of_generations=50,\n",
    "        population_size=100,\n",
    "    ):\n",
    "        self.population_size = population_size\n",
    "        self.number_of_generations = number_of_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.function_to_optimize = None\n",
    "        self.population = None\n",
    "        self.problem_dim = None\n",
    "        self.hall_of_fame = []\n",
    "\n",
    "    def _generate_population(self, n_genes):\n",
    "        self.population = np.random.uniform(-10, 10, (self.population_size, n_genes))\n",
    "\n",
    "    def _mutation(self, individual):\n",
    "        for i in range(len(individual)):\n",
    "            if np.random.rand() < self.mutation_rate:\n",
    "                individual += np.random.normal(0, 1, self.problem_dim)\n",
    "        return individual\n",
    "\n",
    "    def _crossover(self, parent1, parent2):\n",
    "        if np.random.rand() < self.crossover_rate:\n",
    "            crossover_point = np.random.randint(1, self.problem_dim - 1)\n",
    "            child1 = np.concatenate(\n",
    "                (parent1[:crossover_point], parent2[crossover_point:])\n",
    "            )\n",
    "            child2 = np.concatenate(\n",
    "                (parent2[:crossover_point], parent1[crossover_point:])\n",
    "            )\n",
    "            return child1, child2\n",
    "        return parent1, parent2\n",
    "\n",
    "    def _evaluate_population(self):\n",
    "        fitness = np.zeros(len(self.population))\n",
    "        for i, individual in enumerate(self.population):\n",
    "            fitness[i] = self.function_to_optimize(*individual)\n",
    "        self.hall_of_fame.append(np.argsort(fitness)[: int(self.population_size * 0.1)])\n",
    "        return fitness\n",
    "\n",
    "    def _tournament_selection(self, fitness):\n",
    "        fitness = 1 / fitness\n",
    "        probabilities = fitness / np.sum(fitness)\n",
    "        return self.population[\n",
    "            np.random.choice(\n",
    "                range(len(self.population)),\n",
    "                p=probabilities,\n",
    "                size=self.population_size - len(self.hall_of_fame[-1]),\n",
    "                replace=True,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def _select_individual(self, n=1):\n",
    "        return self.population[\n",
    "            np.random.choice(range(self.population_size), size=n, replace=False)\n",
    "        ]\n",
    "\n",
    "    def _visualize_individual(self, individual):\n",
    "        print(individual)\n",
    "\n",
    "    def optimize(self, function_to_optimize, silent=False):\n",
    "        # initialize the population\n",
    "        self.function_to_optimize = function_to_optimize\n",
    "        self.problem_dim = function_to_optimize.__code__.co_argcount\n",
    "        self._generate_population(self.problem_dim)\n",
    "        best_evaluation_in_iteration = []\n",
    "        best_solution_in_iteration = []\n",
    "\n",
    "        # main algorithm loop\n",
    "        for generation in range(self.number_of_generations):\n",
    "\n",
    "            # crossover\n",
    "            children = np.zeros(\n",
    "                (2 * len(range(0, self.population_size, 2)), self.problem_dim)\n",
    "            )\n",
    "            for i in range(0, self.population_size, 2):\n",
    "                parent1, parent2 = self._select_individual(n=2)\n",
    "                children[i], children[i + 1] = self._crossover(parent1, parent2)\n",
    "            self.population = np.vstack([self.population, children])\n",
    "\n",
    "            # mutation\n",
    "            # we mutate every individual in the population not random one\n",
    "            mutated = np.zeros((self.population_size, self.problem_dim))\n",
    "            for i in range(self.population_size):\n",
    "                individual = self._select_individual()\n",
    "                mutated[i] = self._mutation(individual)\n",
    "            self.population = np.vstack([self.population, mutated])\n",
    "\n",
    "            # evaluate the population and log the best solution\n",
    "            fitness = self._evaluate_population()\n",
    "            if not silent:\n",
    "                print(\n",
    "                    f\"iter: {generation}, best: {np.min(fitness)} for {['%.3f' % n for n in self.population[self.hall_of_fame[-1][0]]]}\"\n",
    "                )\n",
    "\n",
    "            best_evaluation_in_iteration.append(np.min(fitness))\n",
    "            best_solution_in_iteration.append(self.population[self.hall_of_fame[-1][0]])\n",
    "\n",
    "            # create new population\n",
    "            self.population = np.vstack(\n",
    "                [\n",
    "                    self.population[self.hall_of_fame[-1]],\n",
    "                    self._tournament_selection(fitness),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return best_evaluation_in_iteration, best_solution_in_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "auto_mpg = fetch_ucirepo(id=9)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = auto_mpg.data.features\n",
    "y = auto_mpg.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "iris = fetch_ucirepo(id=53)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = iris.data.features\n",
    "y = iris.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_large_train = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/nizwant/miowid/main/data/regression/multimodal-large-training.csv\"\n",
    ")\n",
    "multimodal_large_test = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/nizwant/miowid/main/data/regression/multimodal-large-test.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = multimodal_large_train.mean()\n",
    "std = multimodal_large_train.std()\n",
    "multimodal_large_train = (multimodal_large_train - mean) / std\n",
    "multimodal_large_test = (multimodal_large_test - mean) / std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algorytmyistdanych",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
